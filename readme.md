
# Generative Models as a Complex Systems Science: How can we make sense of large language model behavior?

### Ari Holtzman, Peter West, and Luke Zettlemoyer

[paper](How_can_we_make_make_sense_of_large_language_model_behavior?.pdf)

### Abstract
Coaxing out desired behavior from pretrained models, while avoiding undesirable ones, has redefined NLP and is reshaping how we interact with computers. What was once a scientific engineering discipline—in which building blocks are stacked one on top of the other—is arguably already a complex systems science—in which \textit{emergent behaviors} are sought out to support previously unimagined use cases. 

Despite the ever increasing number of benchmarks that measure _task performance_, we lack explanations of what _behaviors_ language models exhibit that allow them to complete these tasks in the first place. 
We argue for a systematic effort to decompose language model behavior into categories that explain cross-task performance, to guide mechanistic explanations and help future-proof analytic research.


### Citation
```
@article{holtzman2023generativemodels,
  title         = "Generative Models as a Complex Systems Science: How can we make sense of large language model behavior?",
  author        = "Holtzman, Ari and West, Peter and Zettlemoyer, Luke",
  year          =  2023,
  jourlnal      =  {preprint}
}
```
